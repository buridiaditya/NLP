{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/du0/15CS30008/anaconda3/envs/nlp/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse import DependencyGraph, DependencyEvaluator\n",
    "from nltk.parse.transitionparser import TransitionParser, Configuration, Transition\n",
    "import tempfile, os\n",
    "from os import remove\n",
    "import re\n",
    "import pickle\n",
    "try:\n",
    "    from numpy import array\n",
    "    from scipy import sparse\n",
    "    from sklearn.datasets import load_svmlight_file\n",
    "    from sklearn import svm\n",
    "    from sklearn import linear_model\n",
    "    from sklearn import neural_network\n",
    "except ImportError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionParserCustom(TransitionParser):\n",
    "    def train(self, depgraphs, modelfile,modelType='logistic', njobs = 1,verbose=True):\n",
    "        \"\"\"\n",
    "        :param depgraphs : list of DependencyGraph as the training data\n",
    "        :type depgraphs : DependencyGraph\n",
    "        :param modelfile : file name to save the trained model\n",
    "        :type modelfile : str\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            input_file = tempfile.NamedTemporaryFile(\n",
    "                prefix='transition_parse.train',\n",
    "                dir=tempfile.gettempdir(),\n",
    "                delete=False)\n",
    "\n",
    "            if self._algorithm == self.ARC_STANDARD:\n",
    "                self._create_training_examples_arc_std(depgraphs, input_file)\n",
    "            else:\n",
    "                self._create_training_examples_arc_eager(depgraphs, input_file)\n",
    "\n",
    "            input_file.close()\n",
    "            # Using the temporary file to train the libsvm classifier\n",
    "            x_train, y_train = load_svmlight_file(input_file.name)\n",
    "            model = None\n",
    "            if modelType == 'logistic': \n",
    "                model = linear_model.LogisticRegression(\n",
    "                    C=0.5,\n",
    "                    verbose=verbose,\n",
    "                    n_jobs=njobs,\n",
    "                    solver='lbfgs'\n",
    "                )\n",
    "            elif modelType == 'MLP':\n",
    "                model = neural_network.MLPClassifier(hidden_layer_sizes=(100,50),learning_rate='adaptive',max_iter=500)\n",
    "            elif modelType == 'SVM':\n",
    "                model = svm.SVC(\n",
    "                kernel='poly',\n",
    "                degree=2,\n",
    "                coef0=0,\n",
    "                gamma=0.2,\n",
    "                C=0.5,\n",
    "                verbose=verbose,\n",
    "                probability=True)\n",
    "\n",
    "            \n",
    "            model.fit(x_train, y_train)\n",
    "            # Save the model to file name (as pickle)\n",
    "            pickle.dump(model, open(modelfile, 'wb'))\n",
    "        finally:\n",
    "            os.remove(input_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFile = \"./UD_Hindi/hi-ud-train.conllu\"\n",
    "testFile = \"./UD_Hindi/hi-ud-test.conllu\"\n",
    "\n",
    "\n",
    "def loadDataIntoDependencyGraph(trainFile, testFile, haveMorphoFeatures = True):\n",
    "    ## This function reads the training and test data.\n",
    "    #  It creates dependency graph based on requirement of morphological features.\n",
    "    fd = open(trainFile)\n",
    "    trainData = []\n",
    "    graph = \"\"\n",
    "    for line in fd:\n",
    "        if line.strip() == \"\":\n",
    "            trainData.append(graph)\n",
    "            graph = \"\"\n",
    "            continue\n",
    "\n",
    "        cols = re.split(\"\\t\",line)\n",
    "        if haveMorphoFeatures:\n",
    "            cols[5] = cols[5] + '|' + cols[9][:-1]\n",
    "        else:\n",
    "            cols[5] = '_'\n",
    "        #print(cols)\n",
    "        finalLine = \"\"\n",
    "        for i in cols:\n",
    "            finalLine += i + \"\\t\"\n",
    "        finalLine = finalLine[:-1]\n",
    "        finalLine += \"\\n\"\n",
    "        graph = graph + finalLine\n",
    "\n",
    "    fd = open(testFile)\n",
    "    testData = []\n",
    "    graph = \"\"\n",
    "    for line in fd:\n",
    "        if line.strip() == \"\":\n",
    "            testData.append(graph)\n",
    "            graph = \"\"\n",
    "            continue\n",
    "\n",
    "        cols = re.split(\"\\t\",line)\n",
    "        if haveMorphoFeatures:\n",
    "            cols[5] = cols[5] + '|' + cols[9][:-1]\n",
    "        else:\n",
    "            cols[5] = '_'\n",
    "        #print(cols)\n",
    "        finalLine = \"\"\n",
    "        for i in cols:\n",
    "            finalLine += i + \"\\t\"\n",
    "        finalLine = finalLine[:-1]\n",
    "        finalLine += \"\\n\"\n",
    "        graph = graph + finalLine\n",
    "    \n",
    "    trainDataGraph = []\n",
    "    for t in trainData:\n",
    "        d = DependencyGraph(t)\n",
    "        trainDataGraph.append(d)\n",
    "\n",
    "    testDataGraph = []\n",
    "    for t in testData:\n",
    "        d = DependencyGraph(t)\n",
    "        testDataGraph.append(d)    \n",
    "\n",
    "    return trainDataGraph, testDataGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/du0/15CS30008/anaconda3/envs/nlp/lib/python3.7/site-packages/nltk/parse/dependencygraph.py:380: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  \"The graph doesn't contain a node \"\n"
     ]
    }
   ],
   "source": [
    "# With morphological features\n",
    "trainDataGraphMorpho, testDataGraphMorpho = loadDataIntoDependencyGraph(trainFile,testFile)\n",
    "#Without morphological features\n",
    "trainDataGraph, testDataGraph = loadDataIntoDependencyGraph(trainFile,testFile,haveMorphoFeatures=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Transition parser using arc-standard and SVM classifier\n",
    "##\n",
    "\n",
    "parser_std = TransitionParserCustom('arc-standard')\n",
    "\n",
    "# Training on training data with morphological feautures\n",
    "parser_std.train(trainDataGraph,'temp.arcstd.model',modelType='SVM', verbose=False)\n",
    "result_std = parser_std.parse(testDataGraph, 'temp.arcstd.model')\n",
    "\n",
    "# Training on training data without morphological feautures\n",
    "parser_std.train(trainDataGraphMorpho,'temp.arcstd.morpho.model',modelType='SVM', verbose=False)\n",
    "result_std_morpho = parser_std.parse(testDataGraphMorpho, 'temp.arcstd.morpho.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Transition parser using arc-eager and SVM classifier\n",
    "##\n",
    "\n",
    "parser_eager = TransitionParserCustom('arc-eager')\n",
    "\n",
    "# Training on training data with morphological feautures\n",
    "parser_eager.train(trainDataGraph,'temp.arceager.model',modelType='SVM', verbose=False)\n",
    "result_eager = parser_eager.parse(testDataGraph, 'temp.arceager.model')\n",
    "\n",
    "# Training on training data without morphological feautures\n",
    "parser_eager.train(trainDataGraphMorpho,'temp.arceager.morpho.model',modelType='SVM', verbose=False)\n",
    "result_eager_morpho = parser_eager.parse(testDataGraphMorpho, 'temp.arceager.morpho.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "de1 = DependencyEvaluator(result_std, testDataGraph)\n",
    "de2 = DependencyEvaluator(result_std_morpho, testDataGraphMorpho)\n",
    "de3 = DependencyEvaluator(result_eager, testDataGraph)\n",
    "de4 = DependencyEvaluator(result_eager_morpho, testDataGraphMorpho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(de1.eval())\\nprint(de2.eval())\\nprint(de3.eval())\\nprint(de4.eval())\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(de1.eval())\n",
    "print(de2.eval())\n",
    "print(de3.eval())\n",
    "print(de4.eval())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Transition parser using arc-standard and logistic classifier\n",
    "##\n",
    "\n",
    "parser_std = TransitionParserCustom('arc-standard')\n",
    "\n",
    "# Training on training data with morphological feautures\n",
    "parser_std.train(trainDataGraph,'temp.arcstd.model',njobs=48, verbose=False)\n",
    "result_std_logistic = parser_std.parse(testDataGraph, 'temp.arcstd.model')\n",
    "\n",
    "# Training on training data without morphological feautures\n",
    "parser_std.train(trainDataGraphMorpho,'temp.arcstd.morpho.model',njobs=48, verbose=False)\n",
    "result_std_morpho_logistic = parser_std.parse(testDataGraphMorpho, 'temp.arcstd.morpho.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Transition parser using arc-eager and logistic classifier\n",
    "##\n",
    "\n",
    "parser_eager = TransitionParserCustom('arc-eager')\n",
    "\n",
    "# Training on training data with morphological feautures\n",
    "parser_eager.train(trainDataGraph,'temp.arceager.model', njobs=48, verbose=False)\n",
    "result_eager_logistic = parser_eager.parse(testDataGraph, 'temp.arceager.model')\n",
    "\n",
    "# Training on training data without morphological feautures\n",
    "parser_eager.train(trainDataGraphMorpho,'temp.arceager.morpho.model',njobs=48, verbose=False)\n",
    "result_eager_morpho_logistic = parser_eager.parse(testDataGraphMorpho, 'temp.arceager.morpho.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "de5 = DependencyEvaluator(result_std_logistic, testDataGraph)\n",
    "de6 = DependencyEvaluator(result_std_morpho_logistic, testDataGraphMorpho)\n",
    "de7 = DependencyEvaluator(result_eager_logistic, testDataGraph)\n",
    "de8 = DependencyEvaluator(result_eager_morpho_logistic, testDataGraphMorpho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(de5.eval())\\nprint(de6.eval())\\nprint(de7.eval())\\nprint(de8.eval())\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(de5.eval())\n",
    "print(de6.eval())\n",
    "print(de7.eval())\n",
    "print(de8.eval())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Transition parser using arc-standard and MLP classifier\n",
    "##\n",
    "\n",
    "parser_std = TransitionParserCustom('arc-standard')\n",
    "\n",
    "# Training on training data with morphological feautures\n",
    "parser_std.train(trainDataGraph,'temp.arcstd.model', modelType='MLP',verbose=False)\n",
    "result_std_mlp = parser_std.parse(testDataGraph, 'temp.arcstd.model')\n",
    "\n",
    "# Training on training data without morphological feautures\n",
    "parser_std.train(trainDataGraphMorpho,'temp.arcstd.morpho.model',modelType='MLP', verbose=False)\n",
    "result_std_morpho_mlp = parser_std.parse(testDataGraphMorpho, 'temp.arcstd.morpho.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Transition parser using arc-eager and MLP classifier\n",
    "##\n",
    "\n",
    "parser_eager = TransitionParserCustom('arc-eager')\n",
    "\n",
    "# Training on training data with morphological feautures\n",
    "parser_eager.train(trainDataGraph,'temp.arceager.model',modelType='MLP', verbose=False)\n",
    "result_eager_mlp = parser_eager.parse(testDataGraph, 'temp.arceager.model')\n",
    "\n",
    "# Training on training data without morphological feautures\n",
    "parser_eager.train(trainDataGraphMorpho,'temp.arceager.morpho.model',modelType='MLP', verbose=False)\n",
    "result_eager_morpho_mlp = parser_eager.parse(testDataGraphMorpho, 'temp.arceager.morpho.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "de9 = DependencyEvaluator(result_std_mlp, testDataGraph)\n",
    "de10 = DependencyEvaluator(result_std_morpho_mlp, testDataGraphMorpho)\n",
    "de11 = DependencyEvaluator(result_eager_mlp, testDataGraph)\n",
    "de12 = DependencyEvaluator(result_eager_morpho_mlp, testDataGraphMorpho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(de9.eval())\\nprint(de10.eval())\\nprint(de11.eval())\\nprint(de12.eval())\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(de9.eval())\n",
    "print(de10.eval())\n",
    "print(de11.eval())\n",
    "print(de12.eval())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM based Transition Parser:\n",
      "(Without morphological features) arc-standard :  (0.8495842781557067, 0.7671957671957672)  arc-eager :  (0.8677248677248677, 0.7732426303854876)\n",
      "(With morphological features) arc-standard :  (0.9138321995464853, 0.8329554043839759)  arc-eager :  (0.9108087679516251, 0.8269085411942555)\n",
      "Logistic regression based Transition Parser:\n",
      "(Without morphological features) arc-standard :  (0.7928949357520786, 0.6817838246409675)  arc-eager :  (0.8435374149659864, 0.7278911564625851)\n",
      "(With morphological features) arc-standard :  (0.8669690098261527, 0.7671957671957672)  arc-eager :  (0.9024943310657596, 0.8027210884353742)\n",
      "MLP based Transition Parser:\n",
      "(Without morphological features) arc-standard :  (0.7951625094482238, 0.6848072562358276)  arc-eager :  (0.8208616780045351, 0.6931216931216931)\n",
      "(With morphological features) arc-standard :  (0.8609221466364324, 0.7679516250944822)  arc-eager :  (0.8480725623582767, 0.7558578987150416)\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM based Transition Parser:\")\n",
    "print(\"(Without morphological features) arc-standard : \",de1.eval(),\" arc-eager : \", de3.eval())\n",
    "print(\"(With morphological features) arc-standard : \",de2.eval(),\" arc-eager : \", de4.eval())\n",
    "\n",
    "print(\"Logistic regression based Transition Parser:\")\n",
    "print(\"(Without morphological features) arc-standard : \",de5.eval(),\" arc-eager : \", de7.eval())\n",
    "print(\"(With morphological features) arc-standard : \",de6.eval(),\" arc-eager : \", de8.eval())\n",
    "\n",
    "print(\"MLP based Transition Parser:\")\n",
    "print(\"(Without morphological features) arc-standard : \",de9.eval(),\" arc-eager : \", de11.eval())\n",
    "print(\"(With morphological features) arc-standard : \",de10.eval(),\" arc-eager : \", de12.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
